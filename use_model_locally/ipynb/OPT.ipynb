{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "!pip install -U flash-attn --no-build-isolation\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "OPT.: APT.",
   "id": "1ab5ec496dce0d0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from transformers import OPTForCausalLM, GPT2Tokenizer\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = OPTForCausalLM.from_pretrained(\"facebook/opt-350m\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "\n",
    "prompt = (\"A chat between a curious human and the Statue of Liberty.\\n\\nHuman: What is your name?\\nStatue: I am the \"\n",
    "\n",
    "model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "model.to(device)\n",
    "\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=30, do_sample=False)\n",
    "tokenizer.batch_decode(generated_ids)[0]"
   ],
   "id": "8730cef05b834db2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import OPTForCausalLM\n",
    "model = OPTForCausalLM.from_pretrained(\"facebook/opt-350m\", torch_dtype=torch.float16, attn_implementation=\"sdpa\")\n"
   ],
   "id": "9537b1b1fdf1b634"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import OPTConfig, OPTModel\n",
    "\n",
    "# Initializing a OPT facebook/opt-large style configuration\n",
    "configuration = OPTConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the facebook/opt-large style configuration\n",
    "model = OPTModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ],
   "id": "3fbdfd9a5a08b36e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer, OPTModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "model = OPTModel.from_pretrained(\"facebook/opt-350m\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ],
   "id": "d259e188d52e5661"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer, OPTForCausalLM\n",
    "\n",
    "model = OPTForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "\n",
    "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ],
   "id": "ed18a563754b1499"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "etc...",
   "id": "4653b4337d05e732"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, OPTForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ArthurZ/opt-350m-dummy-sc\")\n",
    "model = OPTForSequenceClassification.from_pretrained(\"ArthurZ/opt-350m-dummy-sc\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]\n",
    "\n",
    "# To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\n",
    "num_labels = len(model.config.id2label)\n",
    "model = OPTForSequenceClassification.from_pretrained(\"ArthurZ/opt-350m-dummy-sc\", num_labels=num_labels)\n",
    "\n",
    "labels = torch.tensor([1])\n",
    "loss = model(**inputs, labels=labels).loss\n",
    "round(loss.item(), 2)"
   ],
   "id": "5692e8e992fcd61d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
